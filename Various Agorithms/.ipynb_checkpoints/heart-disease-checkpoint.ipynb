{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\vvd09\\AppData\\Local\\Programs\\Python\\Python39\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/vvd09/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>283</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>340</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>243</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>417</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>319</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>126</td>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>134</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>152</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>176</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "5     57    1   0       140   192    0        1      148      0      0.4   \n",
       "6     56    0   1       140   294    0        0      153      0      1.3   \n",
       "7     44    1   1       120   263    0        1      173      0      0.0   \n",
       "8     52    1   2       172   199    1        1      162      0      0.5   \n",
       "9     57    1   2       150   168    0        1      174      0      1.6   \n",
       "10    54    1   0       140   239    0        1      160      0      1.2   \n",
       "11    48    0   2       130   275    0        1      139      0      0.2   \n",
       "12    49    1   1       130   266    0        1      171      0      0.6   \n",
       "13    64    1   3       110   211    0        0      144      1      1.8   \n",
       "14    58    0   3       150   283    1        0      162      0      1.0   \n",
       "15    50    0   2       120   219    0        1      158      0      1.6   \n",
       "16    58    0   2       120   340    0        1      172      0      0.0   \n",
       "17    66    0   3       150   226    0        1      114      0      2.6   \n",
       "18    43    1   0       150   247    0        1      171      0      1.5   \n",
       "19    69    0   3       140   239    0        1      151      0      1.8   \n",
       "20    59    1   0       135   234    0        1      161      0      0.5   \n",
       "21    44    1   2       130   233    0        1      179      1      0.4   \n",
       "22    42    1   0       140   226    0        1      178      0      0.0   \n",
       "23    61    1   2       150   243    1        1      137      1      1.0   \n",
       "24    40    1   3       140   199    0        1      178      1      1.4   \n",
       "25    71    0   1       160   302    0        1      162      0      0.4   \n",
       "26    59    1   2       150   212    1        1      157      0      1.6   \n",
       "27    51    1   2       110   175    0        1      123      0      0.6   \n",
       "28    65    0   2       140   417    1        0      157      0      0.8   \n",
       "29    53    1   2       130   197    1        0      152      0      1.2   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "273   58    1   0       100   234    0        1      156      0      0.1   \n",
       "274   47    1   0       110   275    0        0      118      1      1.0   \n",
       "275   52    1   0       125   212    0        1      168      0      1.0   \n",
       "276   58    1   0       146   218    0        1      105      0      2.0   \n",
       "277   57    1   1       124   261    0        1      141      0      0.3   \n",
       "278   58    0   1       136   319    1        0      152      0      0.0   \n",
       "279   61    1   0       138   166    0        0      125      1      3.6   \n",
       "280   42    1   0       136   315    0        1      125      1      1.8   \n",
       "281   52    1   0       128   204    1        1      156      1      1.0   \n",
       "282   59    1   2       126   218    1        1      134      0      2.2   \n",
       "283   40    1   0       152   223    0        1      181      0      0.0   \n",
       "284   61    1   0       140   207    0        0      138      1      1.9   \n",
       "285   46    1   0       140   311    0        1      120      1      1.8   \n",
       "286   59    1   3       134   204    0        1      162      0      0.8   \n",
       "287   57    1   1       154   232    0        0      164      0      0.0   \n",
       "288   57    1   0       110   335    0        1      143      1      3.0   \n",
       "289   55    0   0       128   205    0        2      130      1      2.0   \n",
       "290   61    1   0       148   203    0        1      161      0      0.0   \n",
       "291   58    1   0       114   318    0        2      140      0      4.4   \n",
       "292   58    0   0       170   225    1        0      146      1      2.8   \n",
       "293   67    1   2       152   212    0        0      150      0      0.8   \n",
       "294   44    1   0       120   169    0        1      144      1      2.8   \n",
       "295   63    1   0       140   187    0        0      144      1      4.0   \n",
       "296   63    0   0       124   197    0        1      136      1      0.0   \n",
       "297   59    1   0       164   176    1        0       90      0      1.0   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "5        1   0     1       1  \n",
       "6        1   0     2       1  \n",
       "7        2   0     3       1  \n",
       "8        2   0     3       1  \n",
       "9        2   0     2       1  \n",
       "10       2   0     2       1  \n",
       "11       2   0     2       1  \n",
       "12       2   0     2       1  \n",
       "13       1   0     2       1  \n",
       "14       2   0     2       1  \n",
       "15       1   0     2       1  \n",
       "16       2   0     2       1  \n",
       "17       0   0     2       1  \n",
       "18       2   0     2       1  \n",
       "19       2   2     2       1  \n",
       "20       1   0     3       1  \n",
       "21       2   0     2       1  \n",
       "22       2   0     2       1  \n",
       "23       1   0     2       1  \n",
       "24       2   0     3       1  \n",
       "25       2   2     2       1  \n",
       "26       2   0     2       1  \n",
       "27       2   0     2       1  \n",
       "28       2   1     2       1  \n",
       "29       0   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "273      2   1     3       0  \n",
       "274      1   1     2       0  \n",
       "275      2   2     3       0  \n",
       "276      1   1     3       0  \n",
       "277      2   0     3       0  \n",
       "278      2   2     2       0  \n",
       "279      1   1     2       0  \n",
       "280      1   0     1       0  \n",
       "281      1   0     0       0  \n",
       "282      1   1     1       0  \n",
       "283      2   0     3       0  \n",
       "284      2   1     3       0  \n",
       "285      1   2     3       0  \n",
       "286      2   2     2       0  \n",
       "287      2   1     2       0  \n",
       "288      1   1     3       0  \n",
       "289      1   1     3       0  \n",
       "290      2   1     3       0  \n",
       "291      0   3     1       0  \n",
       "292      1   2     1       0  \n",
       "293      1   0     3       0  \n",
       "294      0   0     1       0  \n",
       "295      2   2     3       0  \n",
       "296      1   0     2       0  \n",
       "297      1   2     1       0  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas = pd.read_csv(\"heart1.csv\")\n",
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "X = datas.iloc[:,:-1].values\n",
    "y = datas.iloc[:,-1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=101)\n",
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.23313107, -1.40984195, -0.92921994,  2.59068617, -0.36844859,\n",
       "        2.28147501,  0.87935746,  0.65194476,  1.47790748, -0.01945604,\n",
       "       -0.65465367,  1.22682988,  1.17065637])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_trainSc = sc_X.fit_transform(X_train)\n",
    "X_testSc = sc_X.fit_transform(X_test)\n",
    "X_trainSc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticreg = LogisticRegression()\n",
    "logisticreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_preds = logisticreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.77      0.86        31\n",
      "           1       0.81      0.97      0.88        30\n",
      "\n",
      "   micro avg       0.87      0.87      0.87        61\n",
      "   macro avg       0.88      0.87      0.87        61\n",
      "weighted avg       0.88      0.87      0.87        61\n",
      "\n",
      "Confusion Matrix:\n",
      "[[24  7]\n",
      " [ 1 29]]\n",
      "Accuracy Score: \n",
      "0.8688524590163934\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,logistic_preds))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,logistic_preds))\n",
    "\n",
    "print(\"Accuracy Score: \")\n",
    "print(accuracy_score(y_test,logistic_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_model = RandomForestClassifier()\n",
    "forest_model.fit(X_train, y_train)\n",
    "forest_preds = forest_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.68      0.78        31\n",
      "           1       0.74      0.93      0.82        30\n",
      "\n",
      "   micro avg       0.80      0.80      0.80        61\n",
      "   macro avg       0.82      0.81      0.80        61\n",
      "weighted avg       0.83      0.80      0.80        61\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21 10]\n",
      " [ 2 28]]\n",
      "Accuracy Score: \n",
      "0.8032786885245902\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,forest_preds))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,forest_preds))\n",
    "\n",
    "print(\"Accuracy Score: \")\n",
    "print(accuracy_score(y_test,forest_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_trainSc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85        31\n",
      "           1       0.84      0.87      0.85        30\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        61\n",
      "   macro avg       0.85      0.85      0.85        61\n",
      "weighted avg       0.85      0.85      0.85        61\n",
      "\n",
      "Confusion Matrix:\n",
      "[[26  5]\n",
      " [ 4 26]]\n"
     ]
    }
   ],
   "source": [
    "knn_preds = knn.predict(X_testSc)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,knn_preds))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,knn_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x145751cc940>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3QAAAEyCAYAAACyDpLjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xl8VfWd//H3996sNytZgIRAAoQEgohUcEExWDcUl+nYTpfptHacsZ3qtNZpVVq1jlop2tp2ZuivOp3u07GLrQviVmvigragiJSEhAABwpabBLLv9/v7I4lFZLkh995z7s3r+XjwMDn33O/3c5KcmM853/P5GGutAAAAAADRx+N0AAAAAACAU0NCBwAAAABRioQOAAAAAKIUCR0AAAAARCkSOgAAAACIUiR0AAAAABClSOgAAAAAIEqR0AEAAABAlCKhAwAAAIAoFed0AEfLycmxRUVFTocBAAAAAI548803m6y1ucHs67qErqioSBs2bHA6DAAAAABwhDFmV7D7suQSAAAAAKIUCR0AAAAARCkSOgAAAACIUiR0AAAAABClSOgAAAAAIEqR0AEAAABAlCKhAwAAAIAo5bo+dG7zxMYGrX5qk+q6rIp9RjdeNV/XLChwOiwAAAAAIKE7kSc2NuhbP39Fqx5bqUUNVVpfUKbbDq+QtISkDgAAAIDjWHJ5Aquf2qRVj63U4t2bFR8Y1OLdm7XqsZVa/dQmp0MDAAAAABK6E6nrslrUUPWebYsaqlTXZR2KCAAAAAD+ioTuBIp9RusLyt6zbX1BmYp9xqGIAAAAAOCvSOhO4Mar5uu2a1do3bR56vd4tW7aPN127QrdeNV8p0MDAAAAAIqinMhQ4ZMlujszXds6rbJsn+76+FkURAEAAADgCtyhO4lrFhTo+buW67LT8pQ5KYtkDgAAAIBrkNAFqTDHpz0t3RoMUBAFAAAAgDuQ0AVpenaK+gYD2t/a7XQoAAAAACCJhC5ohdkpkqT6pi6HIwEAAACAISR0QSrK8UmS6ps7HY4EAAAAAIaQ0AVpUlqSEuM82kVCBwAAAMAlSOiC5PEYFWWnaCdLLgEAAAC4BAndKBRm+7hDBwAAAMA1SOhGoSgnRbtauhSgdQEAAAAAFyChG4Wi7BT1DQS0v63H6VAAAAAAgIRuNIqyhypd7mpi2SUAAAAA55HQjUJhznAvumYKowAAAABwHgndKOSlJykhzkMvOgAAAACuQEI3Ch6PUWGWT/UsuQQAAADgAkEldMaYZcaYGmNMnTHm9mO8fosxpsoY844x5kVjTOHw9jOMMa8bY7YMv/bRUB9ApBVmp2gXSy4BAAAAuMBJEzpjjFfSakmXSyqT9HFjTNlRu22UtNBae7qk30p6YHh7l6RPWWvnSlom6bvGmMxQBe+EomyfdrV00roAAAAAgOOCuUN3lqQ6a+0Oa22fpEclXXPkDtbal6y1I7et3pBUMLy91lq7bfjjfZIaJeWGKngnFOWkqKc/oIPttC4AAAAA4KxgEropkvYc8XnD8LbjuV7SM0dvNMacJSlB0vZjvHaDMWaDMWaD3+8PIiTnFGUPV7psYtklAAAAAGcFk9CZY2w75npDY8wnJS2U9OBR2/Mk/VzSZ6y1gfcNZu0j1tqF1tqFubnuvoFXONKLjkqXAAAAABwWF8Q+DZKmHvF5gaR9R+9kjLlY0tcklVtre4/Yni7paUl3WGvfGFu4zsvPTFaC16OdJHQAAAAAHBbMHbr1kmYZY6YbYxIkfUzSk0fuYIxZIOlhSVdbaxuP2J4g6feSfmat/U3ownaO12M0NStZu1hyCQAAAMBhJ03orLUDkm6S9Jykakm/ttZuMcbcY4y5eni3ByWlSvqNMeZtY8xIwvd3ki6QdN3w9reNMWeE/jAiqyg7hebiAAAAABwXzJJLWWvXSlp71La7jvj44uO87xeSfjGWAN2oKCdF67Y3y1orY471iCEAAAAAhF9QjcXxXkXZPnX3D6qxvffkOwMAAABAmJDQnYLCd1sXsOwSAAAAgHNI6E7BSC+6Xc0URgEAAADgHBK6U5CfmaR4r6F1AQAAAABHkdCdgjivR1Mn+GguDgAAAMBRJHSnqDDbp3p60QEAAABwEAndKSrKGepFZ611OhQAAAAA4xQJ3Skqyk5RV9+g/B20LgAAAADgDBK6U1SY7ZNEpUsAAAAAziGhO0XTc4ZaF+ykFx0AAAAAh5DQnaIpmcmK8xgqXQIAAABwDAndKYrzelQwIVn1LLkEAAAA4BASujEozE7hDh0AAAAAx5DQjcH0nBTVN3XRugAAAACAI0joxqAw26eO3gE1d/Y5HQoAAACAcYiEbgyKsocqXbLsEgAAAIATSOjGoOjd1gUURgEAAAAQeSR0YzAlM1leWhcAAAAAcAgJ3RgkxHk0JZPWBQAAAACcQUI3RkU5Kapv4g4dAAAAgMgjoRujomyf6ps7aV0AAAAAIOJI6MaoMDtF7T0DOtTV73QoAAAAAMYZEroxKsr2SZJ2suwSAAAAQISR0I3RSOsCKl0CAAAAiDQSujEqmJAsjxGVLgEAAABEHAndGCXGeZWfmcwdOgAAAAARR0IXAtNpXQAAAADAASR0IVCY7WPJJQAAAICII6ELgaLsFLV29+twV5/ToQAAAAAYR0joQqAoe6jSJa0LAAAAAEQSCV0IFOUM9aLbxbJLAAAAABFEQhcCBRN8Mkaqp9IlAAAAgAgioQuBpHiv8jOSqXQJAAAAIKJI6EKkKIdKlwAAAAAiK6iEzhizzBhTY4ypM8bcfozXbzHGVBlj3jHGvGiMKTzitU8bY7YN//t0KIN3k8LsFJqLAwAAAIiokyZ0xhivpNWSLpdUJunjxpiyo3bbKGmhtfZ0Sb+V9MDwe7MkfV3S2ZLOkvR1Y8yE0IXvHkXZPh3q6ldrV7/ToQAAAAAYJ4K5Q3eWpDpr7Q5rbZ+kRyVdc+QO1tqXrLUj6w3fkFQw/PFlkl6w1rZYaw9JekHSstCE7i4jrQsojAIAAAAgUoJJ6KZI2nPE5w3D247neknPjOa9xpgbjDEbjDEb/H5/ECG5T1EOCR0AAACAyAomoTPH2GaPuaMxn5S0UNKDo3mvtfYRa+1Ca+3C3NzcIEJyn2lZ9KIDAAAAEFnBJHQNkqYe8XmBpH1H72SMuVjS1yRdba3tHc17Y8FQ64IkWhcAAAAAiJhgErr1kmYZY6YbYxIkfUzSk0fuYIxZIOlhDSVzjUe89JykS40xE4aLoVw6vC0mFWansOQSAAAAQMTEnWwHa+2AMeYmDSViXkk/stZuMcbcI2mDtfZJDS2xTJX0G2OMJO221l5trW0xxtyroaRQku6x1raE5UhcoCjHp+e3HHQ6DAAAEAFPbGzQ6qc2qa7LqthndONV83XNgoKTvxEYB9x+frg9vtE4aUInSdbatZLWHrXtriM+vvgE7/2RpB+daoDRpDA7Rc2dfWrr6Vd6UrzT4QAAgDB5YmODvvXzV7TqsZVa1FCl9QVluu3wCklLovaPQiBU3H5+uD2+0QqqsTiCM9K6YFcThVEAAIhlq5/apFWPrdTi3ZsVHxjU4t2bteqxlVr91CanQwMc5/bzw+3xjRYJXQgV5QxVuuQ5OgAAYltdl9Wihqr3bFvUUKW6rmMWAgfGFbefH26Pb7RI6EKoMGv4Dh0JHQAAMa3YZ7S+oOw929YXlKnYd6yOTcD44vbzw+3xjRYJXQglJ3g1OT1JO1lyCQBATLvqvFn6wtW3at20eer3eLVu2jz924du141XzXc6NMBx/7TsNH3xqPPjS9fc5prz44Yr5r0vvtuuXeGa+EYrqKIoCF5hto87dAAAxDBrrV7e1qTeCdm66x/v145uKTPQp97EJC0tneR0eIDj6lu65fdl6KvXfUO7e40megZ0cNCr/Ak+p0OTJB1s75Pfl6EVn75Pe/o8KvYZfTnWq1wieEXZKXpxa+PJdwQAAFHpmb8c0Pr6Q7r/Q/P0ibOnSZKq97dp+X+8ou+9uE13XVV2khGA2LWnpUs/fHWnPvSBqfrOR8+QJHX1DeiD36rUvWuq9Pjnz5PH49zSxsb2Hn3/pTpdOjdPj3xqoWNxhBJLLkOsKCdFTR29au/pdzoUAAAQYj39g1r5TLVmT07TRxdNfXf7nLx0fXTRVP3s9Xrt8Hc4FyDgsFXPbpXHSLcuK313my8hTrcuK9U7Da16/O29DkYnffu5WvUNBvTVK+Y4GkcokdCFWFH20K3kXc08RwcAQKz58Wv12tPSrTuWl8l71F2GWy4pVVK8V/evrXYoOsBZG+pbtOad/brhgpnKy0h+z2t/c8YUnV6QoVXPblVX34Aj8W3Z16pfv7lHnz63SEU5KY7EEA4kdCFWONKLjoQOAICY4m/v1eqX6nTR7Ik6f1bO+17PTUvU5y+cqT9UN+q1uiYHIgScEwhY3bumSpPSE/W58hnve93jMbrzyjIdbOvVw5U7Ih6ftUPxZSbH618vmhXx+cOJhC7ECrPpRQcAQCx66IVa9fQP6qvLj79U6x/Pm66CCcm6d02VBgPR2dMKOBVPbNqrTQ2tuvWy2fIlHLtMx6KiLC0/PU8Pv7xd+1u7Ixrf81UH9caOFt1ySYkykuMjOne4kdCFWEpinCamJaq+iYQOAIBYsfVAm361frf+4dxCzcxNPe5+SfFerbh8jrYeaNevN+yJYISAc7r7BvXAszU6vSBDH1ow5YT73r5stgJWevDZmghFJ/UNBLRybbVmTUzVx8+aFrF5I4WELgyKslNYcgkAQIwYWaqVlhSvLwaxVOuKeZO1qGiCvv18DUXSMC488vIO7W/t0R3Ly05awXJqlk/Xnz9dv9u4V5v2HI5IfD97vV71zV362vI5ivPGXvoTe0fkAoXZPpZcAgAQI16sbtRrdc26+eJZyvQlnHR/Y4zuWF6mpo4+rX5pewQiBJxzoLVHP6jcrivmTdZZ07OCes/nl85UTmqC7l1TJWvDuzS5pbNP33txm8pLcrW0dGJY53IKCV0YFOWkqLG9V529zlTwAQAAodE3END9a6s1IzdFnzynMOj3zZ+aqb9dMEU/enWn9rSwagex64HntmowYHX7suDbAKQlxevfLi3Vhl2H9PTm/WGMTvrOC7Xq6hvUHSd49jXakdCFQRGVLgEAiAm/eGOXdjR16o7lcxQ/yqVaX1lWKq/H6JvPbA1TdICz3mk4rN+9tVf/eP50TRsuDBisv1s4VbMnp+mbz2xVT/9gWOLbdrBdv/zzbv392dM0a1JaWOZwAxK6MCh8txcdyy4BAIhWh4aXai2ZlaMLT2GpVl5Gsj5bPkNPb96v9fUtYYgQcM7Is6U5qQm68cKZo36/12N015VlajjUrR+9tjMMEUr3PV0tX4JXN19cEpbx3YKELgxGGhXuJKEDACBqfe/FbWrv6dcdy8tkzIkLPRzPDRfM0OT0JN3zVJUCtDFADFm7+YDW1x/SLZeUKi3p1NoALC7O0cVzJun7L21XY3tPSON7qaZRlbV+ffGiWcpKOfmzr9GMhC4MUhPjlJOaqF1NLLkEACAa1TV26Odv7NLHzpqm0smnvlTLlxCnW5eVavPeVv1+494QRgg4p6d/UCufqdbsyWn66KKpYxrrq1fMVk//oB56vjZE0Un9gwF94+lqFWX79Klzi0I2rluR0IVJEZUuAQCIWvevrZYv3qtbLhn7Uq2/OWOK5hdk6IHntqqrj4JpiH4/fq1eDYe6deeVZfKepE3ByczITdWnFxfpVxv2qGpfW0ji+78/71ZdY4e+esUcJcTFfroT+0fokMLsFBI6AACi0Cvb/Prj1kbd9MFi5aQmjnk8j8fozivLdLCtVw9X7ghBhIBz/O29Wv1SnS6eM1HnFeeEZMwvfHCWMpPjdd/TY29j0NrVr++8UKtzZ2TrkrJJIYnP7UjowmR6jk8H23q5EgcAQBQZGAzovjXVmpbl03XnFYVs3IVFWVp+ep4efnm79rd2h2xcINIeeqFWPf2D+uoVoWsDkOGL180Xl2jd9mb9obpxTGP95x+36XB3v+64cs4pP/sabUjowqRwuHXBbnrPAAAQNR5dv0c1B9u14vLZSozzhnTs25fNVsBKDzxbE9JxgUip3t+mX63frX84t1AzclNDOvYnzp6mmbkp+sbTVeobCJzSGDubOvXT1+v1d2dO1dz8jJDG52YkdGEy0ouuvolllwAARIO2nqGlWmdNz9Ky0yaHfPypWT5df/50/X7jXr2953DIxwfCyVqr+56uUlpSvL540ayQjx/v9eiO5WWqb+7Sz16vP6Ux7l9brQSvR/92WWy3KTgaCV2YFOYM9aKrp7k4AABRYfUf69TS1ac7x9Cm4GQ+v3SmclITdd+asT8rBETSi9WNeq2uWV+6eJYyfeFpA7C0NFcXlOTqP17cpkOdfaN677rtTXqh6qA+f2GxJqYlhSU+tyKhC5P0pHhlpyTQXBwAgCiwq7lTP36tXtd+oEDzCsK3VCstKV5fvrREG3Yd0tOb94dtHiCU+gYCun9ttWbmpujvzykM2zzGGN2xfI46+wb13T8E38ZgMGB175pqTclM1vXnTw9bfG5FQhdGhdk+1dOLDgAA11u5dqvivEZfuaw07HN9ZOFUzclL18q1W9XTPxj2+YCx+vkbu7SjqVNfWz5H8d7wpg8lk9L08bOm6hd/2q26xvag3vPbN/eoen+bbr98tpLiQ/vsazQgoQujohxaFwAA4HZv7GjWs1sO6HPlMzUpPfxLtbweozuXz9Hew936n1d3hn0+YCwOdfbpe3+o1ZJZObqwdGJE5vzSxSXyJXh139PVJ923o3dADz5XqzMLJ+jK0/MiEJ37kNCFUVF2iva39nD1DQAAlwoEhgo95Gck6Z+XzIjYvIuLc3RJ2SR9/6U6Nbb3RGxeYLS+9+I2dfQO6I4wPlt6tOzURH3hg7NUUeNXZa3/hPt+/6U6NXX06s4rIxef25DQhVFh9lBhFFoXAADgTo+91aC/7G3TbZfPVnJCZJdqffWKOeobDOih54N/VgiIpLrGdv38jV36+FnTVDo5LaJzf2pxoQqzfbpvTZUGBo/dxmBPS5d++OpOfWjBFJ0xNTOi8bkJCV0YjbQu2EnrAgAAXKezd0APPFejM6Zm6ur5+RGff3pOij51bpF+tWGPtuxrjfj8wMl84+lq+eK9uuWSyLcBSIzzasXlc7StsUP/t37PMfdZ9exWeYx067LwP/vqZiR0YTSS0FHpEgAA9/lB5Xb5251dqvWFD85SZnK87ltTTRsDuMrLtX69VOPXTR8sVnZqoiMxXDZ3ks6enqWHnq9Ra3f/e17bUN+iNe/s1w0XzFReRrIj8bkFCV0YZfjiNcEXTy86AABcZu/hbj3y8g5dNT9fZxZOcCyODF+8br64RK/vaNYLVQcdiwM40sBgQPc9XaVpWT5dd16RY3EYY3TnlWU63N2v//rjtne3BwJW966p0qT0RH2uPHLPvroVCV2YFWanqJ4llwAAuMoDz26VJN3mgqVanzh7moonpur+tdXqGzj2s0JAJD26fo9qD3boq1fMVmKcs20ATpuSoY+cWaCfrKt/92/qJzbt1aaGVt162Wz5EuIcjc8N+AqE2fScFP15Z4vTYeAEntjYoNVPbVJdl1Wxz+jGq+brmgUFTocVNqE+XreP53Z8/WKb27+/43a8Tquk/m6Vzy9SwQTfKY8XKvFej762fI4+86M/aenXn9SBwTh3f/0YL+bHS+nvUXFeti6bO/mUxwulL19aqic2NujaB5/TIZOg1P4eTcudoA8tmOJ0aO5grT3pP0nLJNVIqpN0+zFev0DSW5IGJH34qNcekLRFUrWk/5BkTjTXmWeeaWPJd16osUW3r7HdfQNOh4JjePytPfb8L/3SvjZtnu3zeO1r0+bZ87/0S/v4W3ucDi0sQn28bh/P7fj6xTa3f38Zz13nx+Nv7bFn/esvXHu8jDf+xlt88/+66vw45wv/69r4wkHSBhtEnmatPfkdOmOMV9JqSZdIapC03hjzpLW26ojddku6TtKXj3rvYknnSTp9eNOrksolVYwy74xaRdkpslZqONSl4omRLfeKk1v91CatemylFu/eLElavHuzVj22UndnpsfkXY3jHe8tScna0TT6Zz1/9VKVHorAeHw/gjPevn5uF63n23gbzy3nx+qnNuk7T6yKuq8f48XueA/+7pu6e0KGa86Pbz/+TdfG57RgllyeJanOWrtDkowxj0q6RtK7CZ21tn74taMXfltJSZISJBlJ8ZLG1RO/RTkjrQtI6NyorstqUUPVe7YtaqhSXVdsVho73vEeHPTqey9uO867js9Yb0TG4/sRnPH29XO7aD3fxtt4bjk/+HlhPDeO5/bzwy3xOS2YhG6KpCObPzRIOjuYwa21rxtjXpK0X0MJ3X9Za6uP3s8Yc4OkGyRp2rRpwQwdNYqGm4vTusCdin1G6wvK3r3iI0nrC8pU7HOmfHW4He94Z6V49Pxdy0c93qX3PB2R8fh+BGe8ff3cLlrPt/E2nlvOD35eGM+N47n9/HBLfI472ZpMSR+R9MMjPv8HSf95nH1/oiOeoZNULOlpSanD/16XdMGJ5ou1Z+istfb0u5+zX/v9O06HgWN4/K09dlEIn1lwu/H2jIbb3fPkZnvmTT8P69fvvBj++rnd42/tsed88X9de34wnrt+v7j9eBmP8Zzk9vjCQaF8hk5Dd+SmHvF5gaR9QeaLH5L0hrW2Q5KMMc9IOkfSy0G+PyYUZftUfwrrmRF+S0omyu9L100fvVuHTLymxAf0lWvPjNn12Jedlqcvp2Tq5k/8u5psvIp9Rl8eQ1Wsofct0d2Z6e9W2QrZeMNV6C46c0ZMfj/6BgJ6catfcZMn6evX36/tXQr59yO5r1sL506Nya9fNLhmQYG+/1K+/uUjX1d7XKK7zzfGc5zbj5fxGM9Jbo/PaWYoATzBDsbESaqVdJGkvZLWS/qEtXbLMfb9iaQ11trfDn/+UUn/rKEqmUbSs5K+a6196njzLVy40G7YsOGUDsatvvjoRr2565Beve2DToeCozzx9l598dG39di/nKvrf7pBF8+ZpG99ZL7TYYVNZa1fn/7Rn/XjzyzShaUTnQ7npK7/yXr9aWeLXvryUuWmJTodTkj98JUduu/pav3kM4u0NEzfixW/e0e/2dCg5750gWbmpoZlDhxfV9+Azvj3F/TpxYX62vIyp8MBAEQRY8yb1tqFwex70sbi1toBSTdJek5DrQd+ba3dYoy5xxhz9fCEi4wxDRpanvmwMWYk2futpO2SNkvaJGnTiZK5WFWYnaJ9h7vVOzDodCg4SmWNXxN88Tpj6gQtmZWrylq/AoHYfcC2oqZRiXEenTsj2+lQgvLV5XPU0z+oh16odTqUkGrp7NP3XtympaW5YUvmJOmWS0qVFO/VyrXve3QZEfD69mb1DQbC+j0GAOCkCZ0kWWvXWmtLrLUzrbXfGN52l7X2yeGP11trC6y1KdbabGvt3OHtg9baz1pr51hry6y1t4TvUNyrKNungJX2tHQ7HQqOEAhYvbzNryWzcuX1GJWX5Mrf3qvqA21OhxY2lbV+nTMjW0nxXqdDCcrM3FT9w7mF+tX63areHzvfl+/+oVZdfYO6Y/mcsM6Tm5aoGy8s1h+qG/XqtqawzoX3q6z1y5fg1cKiCU6HAgCIYUEldBibkdYFVLp0ly372tTU0aelpbmSpPKSof9W1PidDCts9rR0aYe/893jjBZfvGiW0pLidd/TVTrZEvFosO1gu/73T7v192dPi0grk8+cV6SCCcm67+kqDcbw3We3sdaqosavxTOzlRgXHRdQAADRiYQuAoqyhxK6+mYKo7hJRU2jJOmC4QQnNy1Rp01JV2WMJnQjxzuSwEaLTF+Cbr54ll6ra9aL1Y1OhzNm9z1dLV+CVzdfXBKR+ZLivVpx+RxtPdCuX63fc/I3ICR2NnVqd0uXylluCQAIMxK6CJjgi1daUhx36FymstaveVMylJP612Ib5SW5enP3IbX19DsYWXhU1vo1NStZ04fvGEeTT55TqBm5Kbp/bbX6BgJOh3PKKmoaVVnr1xcvmqWslISIzXvFvMlaVDRBD71Qo/YY/Nl2o8raoQtDS6PsjjgAIPqQ0EWAMUbTc1K0s4mEzi1au/r11u5D77tbtbR0ogYDVq/F2PNGvQODWre9WUtLJsqY6GvCGe/16I7lc7SjqVO/eGOX0+GckoHBgL7xdLWm56ToU+cWRXRuY4zuvLJMTR19Wv3S9ojOPV5V1Pg1IzdFU7N8TocCAIhxJHQRUpidol0suXSNV+r8Cli973myBVMzlZYUF3PP0W2oP6SuvsGoW255pAtLJ2rJrBx978VtOtTZ53Q4o/Z/f96tbY0dWnH5bCXERf5X7+kFmfrbD0zRj17dqT0t/C4Kp57+Qb2xY+gCCgAA4UZCFyFF2T41HOqK6uVisaSyxq/0pDidMTXzPdvjvB4tmZWjylp/TBTgGFFR06gEr0fnzoyOdgXHYozRHcvL1N7Tr++9uM3pcEaltatfD71Qq3NnZOuSskmOxXHrZbPl9RitfIY2BuH0xo5m9Q4EVB7FF1AAANGDhC5CCrNTFLBSwyGujDvNWqvKWr+WlOQqzvv+U2BpyUQdaOtRzcF2B6ILj4oav86aniVfQpzToYxJ6eQ0feysafr5G7tU19jhdDhB+88/btPh7n7dceUcR5e8Ts5I0mfLZ2jt5gP6884Wx+KIdRU1fiXFe3T29CynQwEAjAMkdBEyPWfoOQqWXTqven+7Gtt7j1u+f6TqZaxUu9x7uFvbGjuirl3B8dxySYl88V7dHyXNsnc2deqnr9frowunam5+htPh6LMXzFReRpLuXVOlAG0MwuLlKOv3CACIbiR0EVL4busCCqM4raJ2uHz/cRKcyRlJmj05LWaeoxtJTKP5+bkj5aQm6qYPFuuPWxv1yjb3f49Wrq1WgtejWy6NTJuCk0lO8OrWZaXavLdVv9+41+lwYs7u5i7taOqkuiUAIGJI6CIkOyVBqYlxqqfSpeMqavwqy0vXxPSk4+5TXpqrDbta1NE7EMHIwqOytlFTMpNVPDGiTdTxAAAgAElEQVTV6VBC5rrzijQty6f71lRrYNC9z6Wu296k56sO6vMXFmti2vF/3iLtmvlTNL8gQw88t1VdfdH/M+4m714wov8cACBCSOgixBijohwfzcUd1tbTr7d2HTppsYKlJRPVP2i1ri662xf0DQT0Wl2zLijJjcp2BceTGOfVistnq+Zgux51abPswYDVvWuqNSUzWdefP93pcN7D4xlqY3CwrVc/qNzhdDgxpbLGr8Jsn4qisN8jACA6kdBF0FDrAu7QOWldXZMGAvaky6HOLJyg1MQ4VdS6f0nfiby565A6egdiZrnlkZadNllnTc/Sd16odWUj+N++uUfV+9u04orZrnyWamFRlq48PU+PvLxd+1u7nQ4nJvT0j/R7jL3zDQDgXiR0EVSU7dOeQ93qd/ESsVhXWetXWmKcPlA44YT7JcR5tHhmtiprort9QWWtX3Eeo8VR3K7geIwxuuvKMrV09Wn1H+ucDuc9OnoH9OBztVpYOEHL5+U5Hc5x3X75bAWs9MCzNU6HEhM21B9Sd/8g7QoAABFFQhdBRdkpGgxY7T3E1XAnWGtVUePXecU5ij9Gu4KjLS2dqL2Hu7XdHz3l8Y9WUdOohUUTlJYU73QoYXHalAxd+4EC/fi1eu120XLm/1dRp6aOXt15ZZmrl7oWTPDpn86frt9v3Ku39xx2OpyoV1HTqIQ4j86dkeN0KACAcYSELoJGnqmg0qUzag92aH9rT9DLD0euskdrtcuDbT3aeqA95oszfOWyUsV53dMsu+FQl/77lZ360IIpmn9U43o3+vyFxcpJTdS9a6qi+m60G1TU+nX29CwlJ7hviS0AIHaR0EVQYTa96JxUOVx9LtjlUFMykzVrYqoqo/Q5upF2BbHSf+54JqUn6XPlM/XMXw7ojR3NToejbz6zVR4j3bqs1OlQgpKaGKcvX1qiN3cd0pp39jsdTtRqONSluhjq9wgAiB4kdBGUm5qolASvdtK6wBEVNX6VTkpTXkZy0O9ZWpqrP+1oicrS7hW1jZqUnqjZk9OcDiXs/nnJDOVnJOm+p51tlv3mrhateWf/cPPu4H/OnPaRhVM1Jy9d33xmq3r6B50OJyqNXPiJ9TviAAD3IaGLIGMMlS4d0tE7oPX1LaOu9lheMlF9gwG9vt35Oz+jMTAY0CvbmlQeY+0Kjic5wavbLp+tv+xt02NvNTgSQyBgdc+aak1KT9Rny2c4EsOp8nqM7rxyjvYe7tb/vLrT6XCiUkWNX1MykzUzl3YFAIDIIqGLsKIcH0suHfD69mb1D9pRL4daNH2CkuO9UbfscuOew2rvGRhXdwuunp+vM6Zm6sHnatTpQEP4Jzft06Y9h3XrZbPlS4iL+PxjtXhmji4pm6Tvv1SnxvYep8OJKn0DAa2ra9LS0vFxAQUA4C4kdBFWmJ2i3S1dGqB1QURV1DTKl+DVwqKsUb0vMc6rxTOzVRFl7Qsqa/zyeozOKx4/1faMGWqW3djeqx9Ubo/o3N19g1r17FadXpChDy2YEtG5Q+mrV8xR32BA336u1ulQosqGXS3q7BscVxdQAADuQUIXYdOzUzQQsNp3mCvgkWKtVWWtX4tn5ighbvQ/8ktLc7W7pUv1UXRntaK2UR+YlqmM5NhsV3A8ZxZO0NXz8/XIyzu093Dk2oM88vIO7W/t0Z1Xlsnjid47NNNzUvTpc4v06zf3aMu+VqfDiRqVtX7Fe43OjcF+jwAA9yOhi7CRSpe0Loic7f5ONRzqHvXzcyPKS4auulfUNIYyrLBpbO/RX/a2jdu7BbddPluS9MCzWyMy34HWHv2gcruWz8vTolHeAXajf71oljKT43XfmuqouivtpMoavxYVZSk1MfqW2gIAoh8JXYTRiy7yRhKxUy0nPi3bpxk5KVHTj+6V2iZJsd+u4HimZCbrn5fM0BNv79PG3YfCPt+Dz9VoMGB1+3AiGe0ykuP1pUtK9PqOZr1QddDpcFxvf2u3th5oH7fnGwDAeSR0ETYxLVHJ8V7VN0XP8r1oV1nr18zcFE3N8p3yGOWluXpjR3NUlHSvqPUrJzVRZXnpTofimH9ZOlO5aYm6J8zNsjc3tOqxtxr0j+dPH9PPl9t84qxpKp6YqvvXVqtvgOd9T+Rl2hUAABxGQhdhQ60LfLQuiJDuvkH9aWfLmP/YWlo6Ub0DAVc0rj6RwYDVK9v8Ki/JjepnucYqJTFOX7msVBt3H9aTm/aFZQ5rre5Zs0U5qQm68cKZYZnDKXFej+5YPkf1zV362ev1TofjahU1fuVlJKlkUqrToQAAxikSOgcUZaew5DJCXt/RpL6BwCk/Pzfi7OlZSozzuH7Z5aaGwzrc1a/yMR5vLPjwBwo0Nz9dq8LULPuZvxzQ+vpD+rdLS5WWFHvFZ5aWTlR5Sa6+9+I2tXT2OR2OK/UPBvTqOOr3CABwJ57gdkD/wKAO7G3SjNvXqNhndONV83XNggKnw4pJlTV+Jcd7x1ysIineq3NnZr+7vMqtKmr88hhpyThqV3A8Hs9QG4OPPbxOF379KR0MxIXkfHtiY4P+68m3VdclZQz2Kskbu3/I37F8ji77TqWW3fu0mhTP76ujbNx9WO29A2O+YAQAwFiQ0EXYExsbVLWpTv/9+29qUUOV1heU6bbDKyQt4Y+kMKio9evcmdlKiveOeazyklz9+1NV2t3cpWnZ7nxeqrLWr/lTMzUhJcHpUFzhYGu3JnW36dtPrHr3fPvKodu1p2WhyksnjXq8ypqD+r81G/Tg7444fwMr5PHE5vlbta9VE7tb9dDjq/h9dQwVNY2K8xgt5gIKAMBBJHQRtvqpTfr277+pxbs3S5IW796sVY+t1N2Z6fyBFGL1TZ3a1dylfzxvekjGW1o6Uf/+VJUqaxv1D+cWhWTMUGru6NU7DYd180UlTofiGquf2qTvPLHqPefbg7/7pv7J3KlvvTD6pNzX16Uf/m78nL+rn9qkhx5fNW6Od7Qqa/36QOEEpcfgklsAQPQgoYuwui6rRQ1V79m2qKFKdV30ewq1kXYFoVoONT0nRYXZPlXU+F2Z0L1a1yRrQ3e8seB451tPfLJ++KmFox7vhp+uH1fnL7+vjq+xvUdb9rXp1mWlTocCABjnSOgirNhntL6g7N0r3pK0vqBMxb7YfQ7HKRW1/uEkLCVkY5aX5Oo3GxrU0z8YkmWcoVRR41dWSoLmTclwOhTXOO75lmJ0cdnol1wWp4yv85ffV8dXOVwgif5zAACnUeUywm68ar5uu3aF1k2bp36PV+umzdNt167QjVfNdzq0mNLTP6g3djSH/I+tpaW56u4f1Ib68DesHo1AwOrlWr8umJUzrtsVHC3U59t4O3+Pdbz/9qHbY/Z4R6Oy1q/ctPHd7xEA4A7coYuwoedOluiWpGQdHPSq2Gf05avP4HmUEPvTzhb19AdCXr7/nBnZSvB6VFHTqPNnuacQwl/2taq5s492BUcZOd/uzkxXXZcdOt/GUKUx1OO53dHHmxHoU19ikpbOHv3dzVgyMBjQK9uadEnZJNoVAAAcR0LngGsWFCgpIU6f/fmbeuAzi7Vg2gSnQ4o5lTV+JcZ5dO6M7JCO60uI09kzslRZ69cdIR15bCpq/DJGumAWCd3RrllQENKEK9Tjud2Rx7tlX6uu/M9X9Z8vbtMdV5Y5HJlzNjW0qrW7n+dVAQCuENSSS2PMMmNMjTGmzhhz+zFev8AY85YxZsAY8+GjXptmjHneGFNtjKkyxhSFJvToNrJMZ8u+NocjiU0VtY06e0Zo2hUcrbwkV9saO7T3cHfIxz5VlbV+nT4lQ9mpiU6Hghg2Nz9Df3fmVP309XrtbOp0OhzHVNY0Dvd7JKEDADjvpAmdMcYrabWkyyWVSfq4MeboS7O7JV0n6ZfHGOJnkh601s6RdJakxrEEHCsKJiQrPSlOVftJ6EJtT0uXdvg7tTRMxQpGrsqPVNF02uGuPm3cfYjiDIiIf7usRAlej1aurXY6FMdU1Pq1YNoEZfhoVwAAcF4wd+jOklRnrd1hre2T9Kika47cwVpbb619R1LgyO3DiV+ctfaF4f06rLVdoQk9uhljVJafzh26MKioHa4+F6blUDNzUzUlM/ndKndOe2VbkwJWKi+d6HQoGAcmpiXp8xcW6/mqg1q3vcnpcCKuqaNX7zS0hu2CEQAAoxVMQjdF0p4jPm8Y3haMEkmHjTG/M8ZsNMY8OHzH7z2MMTcYYzYYYzb4/e74IzkS5uZnaOv+Ng0MBk6+M4JWWdOoqVnJmpETunYFRzLGqLw0V6/VNalvwPnvXWWtXxnJ8TpjaqbToWCcuP786ZqSmaz71lRrMDC+etK9si28F4wAABitYBK6Y5XwCvb/4HGSlkj6sqRFkmZoaGnmewez9hFr7UJr7cLc3PHzP8myvHT1DgRU3zx+n0UJtd6BQa3b3qylJRPDWn1uaUmuOvsGtWFXS9jmCEYgYFVZ69eSWTny0q4AEZIU79Xtl89W1f42/fbNPSd/QwypqPErJzVBp+XT7xEA4A7BJHQNkqYe8XmBpH1Bjt8gaePwcs0BSY9L+sDoQoxdZfkURgm1DfWH1NU3GPbnyRYX5yjea1RZ6+wd5ar9bfK392opyy0RYVeenqczCyfowedq1dE74HQ4ETH4br/HXPo9AgBcI5iEbr2kWcaY6caYBEkfk/RkkOOvlzTBGDPy1/UHJVWNPszYVDwxVQlej6pI6EKmoqZRCV6PFheHtl3B0VIT47SwMMvx5+hGEsoLStzTEw/jgzFGd15ZpqaOXv2/ijqnw4mIzXtbdairn+WWAABXOWlCN3xn7SZJz0mqlvRra+0WY8w9xpirJckYs8gY0yDpI5IeNsZsGX7voIaWW75ojNmsoeWb/x2eQ4k+8V6PSiancocuhCpr/TprepZ8CeFvsbi0NFdbD7TrQGtP2Oc6nsoav+bmp2tiWpJjMWD8OmNqpv7mjHz99ys71XAo9utdVQ73e1xCv0cAgIsE1YfOWrvWWltirZ1prf3G8La7rLVPDn+83lpbYK1NsdZmW2vnHvHeF6y1p1tr51lrrxuulIlhc/MyVLW/TdaOr8IC4bDvcLdqD3ZErHz/yFX6ylpn2he09fTrzd2HaG4MR926bLY8RvrmM1udDiXsKmobNb8gU1kpCU6HAgDAu4JK6BA+Zfnpauns08G2XqdDiXoVw8sfI5XglE5K0+T0pHfnjbTXtjVpMGBVXsLzc3BOfmaybrhgpta8s19vOlwkKJwOdfbp7T2H6fcIAHAdEjqH/bUwSqvDkUS/ytpG5WckqXhiakTmM8ZoaWmuXt3WpH4HWk9U1PiVlhSnD0yjXQGc9bnyGZqUnqh71lQrEKNtDF6pa5K1kbtgBABAsEjoHDYnbyihozDK2PQNBPRaXbPKS8PbruBo5SW5au8d0MbdhyM2pyRZO9Su4PziHMV5OY3hLF9CnL5y2Wxt2nNYT24KtghydKmoadQEX7xOL+ACCgDAXfhL0GGpiXEqyvZRGGWM3tx1SB29AxG/en7ecP+3iprIPkdXc7BdB9p6uFsA1/jbBVM0b0qGVj27Vd19g06HE1KB4XYFS2bl0u8RAOA6JHQuMDd/qDAKTl1lrV9xHqPFM8PbruBo6UnxOnPahIj3oxtpl8Dzc3ALj2eojcH+1h498vIOp8MJqar9bWrq6OMCCgDAlUjoXKAsP127W7rU1tPvdChRq6KmUQuLJigtKT7ic5eX5mrLvjY1tkeufUFFjV+zJ6dpcgbtCuAeZ03P0hXzJusHldsdbecRaiN34GlXAABwIxI6FxgpjFLNsstTcrCtR1sPtDt2t2rkqv3LtU0Rma+jd0AbdrXQ3BiudPuyORoMWD34XI3ToYRMZa1f86ZkKDct0elQAAB4HxI6F5g7UhiFZZenpDLC7QqOVpaXrty0xIg9R7eurkn9g5by6XCladk+feb8Ij32VoM2N0R/9d7W7n69tZt2BQAA9yKhc4HctETlpCZQGOUUVdQ2alJ6omZPTnNkfmOMykty9cq2Jg1EoH1BRa1fKQleLSzMCvtcwKm46cJiZack6J41W2RtdLcxeHW43yPPzwEA3IqEzgWMMSrLz6B1wSkYGAzolW1NKi/JjWi7gqMtLc1Va3e/NoX5joS1VpU1fp1XnKOEOE5fuFNaUrxuubRE6+sP6Zm/HHA6nDGprG1UelKczphKuwIAgDvxF6FLlOWla1tju/oGIt+gOppt3HNY7T0DWlrqbLXH84tz5DFSZZiXXW73d2jv4W6en4PrfXThVM2enKaVz1Srpz862xiM9HtcMiuXfo8AANfi/1AuMTc/Xf2DVtsa250OJapU1vjl9RidV5zjaByZvgQtiED7gop32xWQ0MHd4rwe3bG8THtauvWTdfVOh3NKth5o18G2Xi6gAABcjYTOJUYqXbLscnQqahv1gWmZykiOfLuCo5WX5Oqdva1q7ugN2xyVtX4VT0xVwQRf2OYAQuX8WTm6aPZE/dcf6+RvD995ES5cQAEARAMSOpcoyk5RcryXwiij0Njeo7/sbXN8ueWIpaW5slZ6eVt47tJ19Q3oTztatJQ/LhFFvrp8jnr6B/XQC7VOhzJqFTWNmpOXrknp9HsEALgXCZ1LeD1Gc/LSaF0wCq8M931zy9Xz0/IzlJ2S8G4bhVB7Y0ez+gYDrklggWDMzE3VJ88p1K/W79bWA9Hz+629p19v7jpEdUsAgOuR0LlIWX66qve1RX2Z70ipqPUrJzVRZcN9/Jzm8RhdUJKrl7c1KRAI/fewosav5HivFk2fEPKxgXC6+eJZSkuK131rqqPm99trdc0aCNDvEQDgfiR0LjI3P0PtvQPa09LtdCiuNxiwemWbX+UlufJ4nGtXcLSlpblq6ezTO3tD277AWquKGr8Wz8xWYpw3pGMD4ZbpS9DNF8/Sq3VN+uPW8FaCDZXK2kalJsbpzEIuoAAA3I2EzkVG7jRV7Q9vL7NYsKnhsA539buu+tySWbkyRiFfdlnf3KXdLV2uO14gWJ88p1AzclP0jaerXd+e5a/9HrMVT7sCAIDLxTkdAP6qdHKavB6jLfvatOy0PMfieGJjg1Y/tUl1XVbFPqMbr5qvaxYUuGq8lb/ZIGO9+o/H35INBMY0XihlpSRoWmayfvzcO/reH2pCdryrfvumjPXoJ89tVkZSnGuOFwhWvNejr10xR9f/5M9a+vWndGDQ69rfL999fKP290imo0NPbJzM+QYAcDUSOhdJivdqZm6Ko60LntjYoG/9/BWtemylFjVUaX1BmW47vELSklP6oyZc4z105Hitpz5eqD2xsUF9+/br+4+vCunxfuvI421zz/ECo9HR3aeJ3W361hOhPT/C+vuqm/MNAOBuxm0PqC9cuNBu2LDB6TAcc/OjG/WnnS16fcVFjsx/6T1P6+7/WaHFuze/u23dtHn67IfvUlJW5qjH62k5rId/e0/Yx7v7+pV6/q7lox4v1CL19XPL8QKjwe8XAACCY4x501q7MJh9uUPnMnPzM/T42/vU0tmnrJSEiM9f12W1qKHqPdsWNVSpIy5JV86ZNOrxHv1TT0TGq+tyx4WJSH393HK8wGjw+wUAgNAjoXOZsvzhwij72nT+rJyIz1/sM1pfUPaeK9TrC8o0K8Vo5d/OG/V4b/5ld0TGK/a5o9JlpL5+bjleYDT4/QIAQOhRvstlRipdbtnnTKXLz11xur5w9a1aN22e+j1erZs2T7ddu0I3XjX/lMa78ar5uu3aFa4dL9TG2/ECo+H284PzDQAQjbhD5zITUhKUn5Gkqv3OFEaZPCFZTb4M3fap+7S336Nin9GXx1A1buh9S3R3Zvq7VejcNF6ojbfjBUbD7ecH5xsAIBpRFMWF/umn67WruUsv3FIe8blXPlOtH726UxvvulSpieT7AAAAQKSNpigKSy5dqCw/Q9v9HeruG4z43JU1fi0szCKZAwAAAKIACZ0LleWlK2ClmoPtEZ13f2u3th5o19LS3IjOCwAAAODUkNC50Nx8ZwqjvFzrlySVk9ABAAAAUYGEzoUKJiQrLSlOVfsiWxilosavyelJKp2UFtF5AQAAAJwaEjoXMsaoLC9dWyKY0PUPBvTqtiYtLc2VMfRcAgAAAKIBCZ1Lzc3P0NYDbRoMRKYK6cbdh9XeO6DyEpZbAgAAANGChM6lyvLT1dMf0M6mzojMV1HTKK/H6LxZORGZDwAAAMDYkdC5VKQLo1TW+nXmtAlKT4qPyHwAAAAAxi6ohM4Ys8wYU2OMqTPG3H6M1y8wxrxljBkwxnz4GK+nG2P2GmP+KxRBjwczc1OV4PWoan/4n6NrbO/Rln1tVLcEAAAAosxJEzpjjFfSakmXSyqT9HFjTNlRu+2WdJ2kXx5nmHslVZ56mONPQpxHsyalRqTS5cu1TZJE/zkAAAAgygRzh+4sSXXW2h3W2j5Jj0q65sgdrLX11tp3JAWOfrMx5kxJkyQ9H4J4x5W5+emq2tcma8NbGKWiplG5aYkqy0sP6zwAAAAAQiuYhG6KpD1HfN4wvO2kjDEeSd+W9JWT7HeDMWaDMWaD3+8PZuhxoSwvXc2dfWps7w3bHAODAb2yrUnlJbQrAAAAAKJNMAndsf7KD/aW0eclrbXW7jnRTtbaR6y1C621C3NzWfY3Yu6UDEnhLYyyqaFVrd39tCsAAAAAolBcEPs0SJp6xOcFkvYFOf65kpYYYz4vKVVSgjGmw1r7vsIqeL/Zk9MkSVX72vTB2ZPCMkdlTaM8RlpCuwIAAAAg6gST0K2XNMsYM13SXkkfk/SJYAa31v79yMfGmOskLSSZC15aUrwKs33aEsbCKBW1fi2YNkGZvoSwzQEAAAAgPE665NJaOyDpJknPSaqW9Gtr7RZjzD3GmKslyRizyBjTIOkjkh42xmwJZ9Djydz89LC1Lmjq6NU7Da0stwQAAACiVDB36GStXStp7VHb7jri4/UaWop5ojF+Iukno45wnCvLS9fazQfU3tOvtBA3/X5l21ABGtoVAAAAANEpqMbicM7c/KHCKNX720M+dmWNX9kpCTpteA4AAAAA0YWEzuXK8od6w1WFuNJlIGD18rYmXVCSK4+HdgUAAABANCKhc7mJaYnKTkkIeWGUd/a2qqWzj+WWAAAAQBQjoXM5Y4zKwlAYpbLGL2OkJbNI6AAAAIBoRUIXBcry07XtYIf6BgIhG7OitlGnF2QqK4V2BQAAAEC0IqGLAnPzM9Q3GFBdY0dIxjvU2adNew7TrgAAAACIciR0UaAsb7gwSoiWXb5S16SApV0BAAAAEO1I6KLA9JwUJcd7tSVElS4rahqV6YvX/ILMkIwHAAAAwBkkdFHA6zGanZemqhBUugwErF6ubdKSWbny0q4AAAAAiGokdFGiLG+o0qW1dkzjVO1vU1NHr5by/BwAAAAQ9UjoosTc/Ay19wyo4VD3mMaprPVLki4goQMAAACiHgldlCjLHyqMMtYG4xU1jTptSrpy0xJDERYAAAAAB5HQRYnSSWnyGKlqDIVRWrv79dbuw1paMjGEkQEAAABwCgldlEhO8GpmbuqYWhe8VtekwYBVOe0KAAAAgJhAQhdFyvLTx1TpsqKmUWlJcVowlXYFAAAAQCwgoYsic/PTta+1R4c6+0b9XmutKmv9WjIrR3Fevu0AAABALOAv+yhSlpchSae07HLrgXYdbOvl+TkAAAAghpDQRZG/VrocfWGUipqhdgU8PwcAAADEDhK6KJKVkqC8jKRTeo6usrZRsyenaVJ6UhgiAwAAAOAEErooU5aXPuoll+09/dpQf0hLS1luCQAAAMQSErooMzc/Xdv9nerpHwz6Pa/VNWsgYFVewnJLAAAAIJaQ0EWZsvx0DQasag60B/2eylq/UhPjtLBoQhgjAwAAABBpJHRRZm7+UKXLLUE+R2etVWVNo84rzlY87QoAAACAmMJf+FGmYEKy0hLjVLU/uEqXdY0d2tfao3LaFQAAAAAxh4QuyhhjNCc/Peg7dCPtCpbSrgAAAACIOSR0UWhufrq27m/XYMCedN+K2kaVTEpVfmZyBCIDAAAAEEkkdFGoLC9d3f2Dqm/uPOF+nb0DWr/zENUtAQAAgBhFQheFgi2M8vr2ZvUNBug/BwAAAMQoErooVDwxVfFeo6qTJHSVtX75Ery0KwAAAABiFAldFEqI82jWxDRt2Xf8SpfWWlXUNmrxzGwlxnkjGB0AAACASCGhi1Jz89NVta9N1h67MMqOpk7taelWOcstAQAAgJhFQhelyvLT1dzZJ3977zFfrxxpV0BBFAAAACBmkdBFqZMVRqmo9WtGboqmZvkiGRYAAACACCKhi1Kz89IkSVX735/Q9fQP6k87mmlXAAAAAMS4oBI6Y8wyY0yNMabOGHP7MV6/wBjzljFmwBjz4SO2n2GMed0Ys8UY844x5qOhDH48S0+K17Qs3zELo7y+o1m9A7QrAAAAAGLdSRM6Y4xX0mpJl0sqk/RxY0zZUbvtlnSdpF8etb1L0qestXMlLZP0XWNM5liDxpCRwihHq6zxKyneo7OnZzkQFQAAAIBICeYO3VmS6qy1O6y1fZIelXTNkTtYa+utte9IChy1vdZau234432SGiWxDjBEyvLSVd/cpY7egfdsr6z165wZ2UqKp10BAAAAEMuCSeimSNpzxOcNw9tGxRhzlqQESduP8doNxpgNxpgNfr9/tEOPW3OnpEuSqo94jm5Xc6d2NnVS3RIAAAAYB4JJ6Mwxth27+dnxBjAmT9LPJX3GWhs4+nVr7SPW2oXW2oW5uSQiwSrLG6p0eeSyy4rhdgX0nwMAAABiXzAJXYOkqUd8XiBpX7ATGGPSJT0t6Q5r7RujCw8nMik9UVkpCe8pjFJZ61dhtk/Tc1IcjAwAAABAJAST0K2XNMsYM90YkyDpY5KeDGbw4f1/L+ln1g5l0OMAAAdhSURBVNrfnHqYOBZjzFBhlOEllz39g1q3vYnllgAAAMA4cdKEzlo7IOkmSc9Jqpb0a2vtFmPMPcaYqyXJGLPIGNMg6SOSHjbGbBl++99JukDSdcaYt4f/nRGWIxmnyvLSVXugQ/2DAa2vb1FPf0DlpSR0AAAAwHgQF8xO1tq1ktYete2uIz5er6GlmEe/7xeSfjHGGHECZfnp6hsMqK6xQxU1fiXEeXTOjGynwwIAAAAQAUE1Fod7zc0fqnRZta9NFTWNOnt6lnwJQeXpAAAAAKIcCV2Um56TqqR4j56vOqDt/k6V8/wcAAAAMG6Q0EU5r8doUmqiXt24U8YG9L9/2KInNjY4HRYAAACACGBtXpR7YmODevft138/vkqLGqq0vqBMt7WvkLRE1yx432ONAAAAAGIId+ii3OqnNumhx1dp8e7Nig8MavHuzVr12EqtfmqT06EBAAAACDMSuihX12W1qKHqPdsWNVSprss6FBEAAACASCGhi3LFPqP1BWXv2ba+oEzFPuNQRAAAAAAihYQuyt141Xzddu0KrZs2T/0er9ZNm6fbrl2hG6+a73RoAAAAAMKMoihRbqjwyRLdnZmuui6rYp/Rl6+aT0EUAAAAYBwgoYsB1ywoIIEDAAD/v737C9GsruM4/v6wakUFZm4RrmXJQkrUFBWCEdsSsZWkQkFi4EVQgYFB/7Sb/oAXXZTeRNAfWy8qk/5KdKGooVeWf6Y0tshqK3PZKUqqG8P8dnF+m0/jzNDF7Pmd5znvFwzPOWfODF/48OU83zm/84ykGXLJpSRJkiQtKQc6SZIkSVpSDnSSJEmStKQc6CRJkiRpSTnQSZIkSdKScqCTJEmSpCXlQCdJkiRJS8qBTpIkSZKWVKqqdw3/I8mfgd/vwq86E/jLLvwe7R4zmRbzmBbzmBbzmBbzmBbzmBbzmJbdyuMlVbX3/zlxcgPdbklyb1W9tncdeoqZTIt5TIt5TIt5TIt5TIt5TIt5TEuPPFxyKUmSJElLyoFOkiRJkpbUKg90X+pdgJ7GTKbFPKbFPKbFPKbFPKbFPKbFPKZl9DxW9hk6SZIkSVp1q3yHTpIkSZJWmgOdJEmSJC2plRzokhxK8qskDye5unc9c5fkaJIHk6wnubd3PXOU5IYkG0keWjh2RpLbkvy6vT6vZ41zsk0en0ryp9Yn60ne1rPGuUhydpI7kxxJ8oskV7Xj9kcHO+Rhf3SS5JlJfpLkZy2TT7fjL01yT+uRbyU5rXetc7BDHoeT/G6hR9Z61zonSfYkeSDJD9v+qP2xcgNdkj3AF4C3AucDlyU5v29VAt5UVWv+n5RuDgOHNh27Gri9qvYDt7d9jeMwT88D4LrWJ2tV9aORa5qrJ4APV9V5wAXAle2aYX/0sV0eYH/08jhwsKpeBawBh5JcAHyWIZP9wN+A93ascU62ywPgows9st6vxFm6CjiysD9qf6zcQAe8Hni4qn5bVf8CbgIu7lyT1FVV3QX8ddPhi4Eb2/aNwCWjFjVj2+ShDqrqWFXd37b/wXBBPgv7o4sd8lAnNfhn2z21fRVwEPh2O26PjGSHPNRJkn3A24GvtP0wcn+s4kB3FvDHhf1H8GLQWwG3Jrkvyft6F6P/emFVHYPhTRTwgs71CD6Y5OdtSaZL/EaW5Bzg1cA92B/dbcoD7I9u2nKydWADuA34DfBYVT3RTvG91og251FVJ3rk2tYj1yV5RscS5+Z64GPAk23/+YzcH6s40GWLY/7loq8Lq+o1DMtgr0zyxt4FSRP0ReBchiU0x4DP9S1nXpI8B/gO8KGq+nvveuZuizzsj46q6t9VtQbsY1gJdd5Wp41b1XxtziPJK4BrgJcDrwPOAD7escTZSHIRsFFV9y0e3uLUk9ofqzjQPQKcvbC/D3i0Uy0CqurR9roBfI/hYqD+jid5EUB73ehcz6xV1fF2kX4S+DL2yWiSnMowPHy9qr7bDtsfnWyVh/0xDVX1GPBjhucbT09ySvuW77U6WMjjUFuuXFX1OPA17JGxXAi8I8lRhse8DjLcsRu1P1ZxoPspsL99usxpwLuBWzrXNFtJnp3kuSe2gbcAD+38UxrJLcAVbfsK4Acda5m9E8NDcyn2ySjasw5fBY5U1ecXvmV/dLBdHvZHP0n2Jjm9bT8LeDPDs413Au9sp9kjI9kmj18u/AEqDM9r2SMjqKprqmpfVZ3DMHPcUVWXM3J/pGr17pC3jzO+HtgD3FBV13YuabaSvIzhrhzAKcA3zGN8Sb4JHADOBI4DnwS+D9wMvBj4A/CuqvKDOkawTR4HGJaTFXAUeP+JZ7h08iR5A3A38CBPPf/wCYbntuyPke2Qx2XYH10keSXDhzrsYbgRcHNVfaZd329iWN73APCedndIJ9EOedwB7GVY7rcOfGDhw1M0giQHgI9U1UVj98dKDnSSJEmSNAeruORSkiRJkmbBgU6SJEmSlpQDnSRJkiQtKQc6SZIkSVpSDnSSJEmStKQc6CRJkiRpSTnQSZIkSdKS+g9YWRhHmthXTwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#find value of k\n",
    "error_rate = []\n",
    "\n",
    "for i in range(1,40):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_trainSc,y_train)\n",
    "    pred_i = knn.predict(X_testSc)\n",
    "    error_rate.append(np.mean(pred_i != y_test))\n",
    "    \n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(range(1,40), error_rate, marker='o', markerfacecolor='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89        31\n",
      "           1       0.87      0.90      0.89        30\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        61\n",
      "   macro avg       0.89      0.89      0.89        61\n",
      "weighted avg       0.89      0.89      0.89        61\n",
      "\n",
      "Confusion Matrix:\n",
      "[[27  4]\n",
      " [ 3 27]]\n",
      "Accuracy Score: \n",
      "0.8852459016393442\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_trainSc,y_train)\n",
    "\n",
    "knn_preds = knn.predict(X_testSc)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,knn_preds))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,knn_preds))\n",
    "\n",
    "print(\"Accuracy Score: \")\n",
    "print(accuracy_score(y_test,knn_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#Support Vector Machine - Linear\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model = SVC(kernel = 'linear')\n",
    "svm_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_preds = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.74      0.82        31\n",
      "           1       0.78      0.93      0.85        30\n",
      "\n",
      "   micro avg       0.84      0.84      0.84        61\n",
      "   macro avg       0.85      0.84      0.83        61\n",
      "weighted avg       0.85      0.84      0.83        61\n",
      "\n",
      "Confusion Matrix:\n",
      "[[23  8]\n",
      " [ 2 28]]\n",
      "Accuracy Score: \n",
      "0.8360655737704918\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,svm_preds))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,svm_preds))\n",
    "\n",
    "print(\"Accuracy Score: \")\n",
    "print(accuracy_score(y_test,svm_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Svm Kernel RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=0,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = SVC(kernel='rbf', random_state=0)\n",
    "svm_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.49      1.00      0.66        30\n",
      "\n",
      "   micro avg       0.49      0.49      0.49        61\n",
      "   macro avg       0.25      0.50      0.33        61\n",
      "weighted avg       0.24      0.49      0.32        61\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 31]\n",
      " [ 0 30]]\n",
      "Accuracy Score: \n",
      "0.4918032786885246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "svm_preds = svm_model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,svm_preds))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,svm_preds))\n",
    "\n",
    "print(\"Accuracy Score: \")\n",
    "print(accuracy_score(y_test,svm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ..................... C=0.1, gamma=1, score=0.5625, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................... C=0.1, gamma=0.1, score=0.5625, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ...... C=0.1, gamma=0.01, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ...... C=0.1, gamma=0.01, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] .................. C=0.1, gamma=0.01, score=0.5625, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ..... C=0.1, gamma=0.001, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ..... C=0.1, gamma=0.001, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ................. C=0.1, gamma=0.001, score=0.5625, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001 .............................................\n",
      "[CV] .... C=0.1, gamma=0.0001, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001 .............................................\n",
      "[CV] .... C=0.1, gamma=0.0001, score=0.6172839506172839, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001 .............................................\n",
      "[CV] ................... C=0.1, gamma=0.0001, score=0.6, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ....................... C=1, gamma=1, score=0.5625, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ..................... C=1, gamma=0.1, score=0.5625, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.5432098765432098, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.5308641975308642, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ....................... C=1, gamma=0.01, score=0.5, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ....... C=1, gamma=0.001, score=0.7160493827160493, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ....... C=1, gamma=0.001, score=0.5802469135802469, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ..................... C=1, gamma=0.001, score=0.55, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ...... C=1, gamma=0.0001, score=0.7037037037037037, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ...... C=1, gamma=0.0001, score=0.6419753086419753, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] .................. C=1, gamma=0.0001, score=0.6375, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ...................... C=10, gamma=1, score=0.5625, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................... C=10, gamma=0.1, score=0.5625, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ...... C=10, gamma=0.01, score=0.49382716049382713, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.5185185185185185, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.475, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.6790123456790124, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.5679012345679012, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.525, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] ..... C=10, gamma=0.0001, score=0.7530864197530864, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] ..... C=10, gamma=0.0001, score=0.6296296296296297, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] ................. C=10, gamma=0.0001, score=0.6625, total=   0.0s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ......... C=100, gamma=1, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ......... C=100, gamma=1, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ..................... C=100, gamma=1, score=0.5625, total=   0.0s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ....... C=100, gamma=0.1, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ....... C=100, gamma=0.1, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ................... C=100, gamma=0.1, score=0.5625, total=   0.0s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ..... C=100, gamma=0.01, score=0.49382716049382713, total=   0.0s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ...... C=100, gamma=0.01, score=0.5185185185185185, total=   0.0s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ................... C=100, gamma=0.01, score=0.475, total=   0.0s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ..... C=100, gamma=0.001, score=0.6049382716049383, total=   0.0s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ..... C=100, gamma=0.001, score=0.6419753086419753, total=   0.0s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] .................. C=100, gamma=0.001, score=0.575, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] .... C=100, gamma=0.0001, score=0.7654320987654321, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] .... C=100, gamma=0.0001, score=0.6790123456790124, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] ................. C=100, gamma=0.0001, score=0.725, total=   0.0s\n",
      "[CV] C=1000, gamma=1 .................................................\n",
      "[CV] ........ C=1000, gamma=1, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=1000, gamma=1 .................................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=1000, gamma=1, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=1000, gamma=1 .................................................\n",
      "[CV] .................... C=1000, gamma=1, score=0.5625, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1 ...............................................\n",
      "[CV] ...... C=1000, gamma=0.1, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1 ...............................................\n",
      "[CV] ...... C=1000, gamma=0.1, score=0.5555555555555556, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1 ...............................................\n",
      "[CV] .................. C=1000, gamma=0.1, score=0.5625, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01 ..............................................\n",
      "[CV] .... C=1000, gamma=0.01, score=0.49382716049382713, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01 ..............................................\n",
      "[CV] ..... C=1000, gamma=0.01, score=0.5185185185185185, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01 ..............................................\n",
      "[CV] .................. C=1000, gamma=0.01, score=0.475, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] .... C=1000, gamma=0.001, score=0.5802469135802469, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] .... C=1000, gamma=0.001, score=0.6296296296296297, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] ................ C=1000, gamma=0.001, score=0.5875, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001 ............................................\n",
      "[CV] ... C=1000, gamma=0.0001, score=0.7530864197530864, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001 ............................................\n",
      "[CV] .... C=1000, gamma=0.0001, score=0.691358024691358, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001 ............................................\n",
      "[CV] ............... C=1000, gamma=0.0001, score=0.7125, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.7s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C':[0.1,1,10,100,1000],'gamma':[1,0.1,0.01,0.001,0.0001]}\n",
    "grid = GridSearchCV(SVC(), param_grid, verbose=3)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'gamma': 0.0001}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = SVC(kernel='rbf', random_state=0, C=100, gamma=0.0001)\n",
    "svm_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.68      0.79        31\n",
      "           1       0.74      0.97      0.84        30\n",
      "\n",
      "   micro avg       0.82      0.82      0.82        61\n",
      "   macro avg       0.85      0.82      0.82        61\n",
      "weighted avg       0.85      0.82      0.82        61\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21 10]\n",
      " [ 1 29]]\n",
      "Accuracy Score: \n",
      "0.819672131147541\n"
     ]
    }
   ],
   "source": [
    "svm_preds = svm_model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,svm_preds))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,svm_preds))\n",
    "\n",
    "print(\"Accuracy Score: \")\n",
    "print(accuracy_score(y_test,svm_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "tree.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.77      0.81        31\n",
      "           1       0.79      0.87      0.83        30\n",
      "\n",
      "   micro avg       0.82      0.82      0.82        61\n",
      "   macro avg       0.82      0.82      0.82        61\n",
      "weighted avg       0.82      0.82      0.82        61\n",
      "\n",
      "Confusion Matrix:\n",
      "[[24  7]\n",
      " [ 4 26]]\n",
      "Accuracy Score: \n",
      "0.819672131147541\n"
     ]
    }
   ],
   "source": [
    "tree_preds = tree.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,tree_preds))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,tree_preds))\n",
    "\n",
    "print(\"Accuracy Score: \")\n",
    "print(accuracy_score(y_test,tree_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = input('age : ')\n",
    "sex = input('sex : ')\n",
    "cp = input('Chest Pain experienced : ')\n",
    "trestbps = input('Resting Blood Pressure : ')\n",
    "chol = input(\"cholestrol : \")\n",
    "fbs = input(\"Fasting blood Pressure : \" )\n",
    "restcg = input(\"Resting electrocardiographic measurement : \")\n",
    "thalach = input(\"maximum heart rate achieved : \")\n",
    "exang = input(\"Exercise induced angina : \")\n",
    "oldpeak = input(\"ST depression induced by exercise relative to rest : \")\n",
    "slope = input(\"the slope of the peak exercise ST segment : \")\n",
    "ca = input(\"The number of major vessels : \")\n",
    "thal = input(\" A blood disorder called thalassemia : \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "age: The person's age in years\n",
    "\n",
    "sex: The person's sex (1 = male, 0 = female)\n",
    "\n",
    "cp: The chest pain experienced (Value 1: typical angina, Value 2: atypical angina, Value 3: non-anginal pain, Value 4: asymptomatic)\n",
    "\n",
    "trestbps: The person's resting blood pressure (mm Hg on admission to the hospital)\n",
    "\n",
    "chol: The person's cholesterol measurement in mg/dl\n",
    "\n",
    "fbs: The person's fasting blood sugar (> 120 mg/dl, 1 = true; 0 = false)\n",
    "\n",
    "restecg: Resting electrocardiographic measurement (0 = normal, 1 = having ST-T wave abnormality, 2 = showing probable or definite left ventricular hypertrophy by Estes' criteria)\n",
    "\n",
    "thalach: The person's maximum heart rate achieved\n",
    "\n",
    "exang: Exercise induced angina (1 = yes; 0 = no)\n",
    "\n",
    "oldpeak: ST depression induced by exercise relative to rest ('ST' relates to positions on the ECG plot. See more here)\n",
    "\n",
    "slope: the slope of the peak exercise ST segment (Value 1: upsloping, Value 2: flat, Value 3: downsloping)\n",
    "\n",
    "ca: The number of major vessels (0-3)\n",
    "\n",
    "thal: A blood disorder called thalassemia (3 = normal; 6 = fixed defect; 7 = reversable defect)\n",
    "\n",
    "target: Heart disease (0 = no, 1 = yes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
