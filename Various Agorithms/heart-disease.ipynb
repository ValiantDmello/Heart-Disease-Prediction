{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas = pd.read_csv(\"heart.csv\")\n",
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "X = datas.iloc[:,:-1].values #Set columns needed for \n",
    "y = datas.iloc[:,-1].values #Set target value to y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data for training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescale data, will be needed for KNN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_trainSc = sc_X.fit_transform(X_train)\n",
    "X_testSc = sc_X.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticreg = LogisticRegression()\n",
    "logisticreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_preds = logisticreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.77      0.86        31\n",
      "           1       0.81      0.97      0.88        30\n",
      "\n",
      "    accuracy                           0.87        61\n",
      "   macro avg       0.88      0.87      0.87        61\n",
      "weighted avg       0.88      0.87      0.87        61\n",
      "\n",
      "Confusion Matrix:\n",
      "[[24  7]\n",
      " [ 1 29]]\n",
      "Accuracy Score: \n",
      "0.8688524590163934\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,logistic_preds))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,logistic_preds))\n",
    "\n",
    "print(\"Accuracy Score: \")\n",
    "print(accuracy_score(y_test,logistic_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_model = RandomForestClassifier()\n",
    "forest_model.fit(X_train, y_train)\n",
    "forest_preds = forest_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.77      0.86        31\n",
      "           1       0.81      0.97      0.88        30\n",
      "\n",
      "    accuracy                           0.87        61\n",
      "   macro avg       0.88      0.87      0.87        61\n",
      "weighted avg       0.88      0.87      0.87        61\n",
      "\n",
      "Confusion Matrix:\n",
      "[[24  7]\n",
      " [ 1 29]]\n",
      "Accuracy Score: \n",
      "0.8688524590163934\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,forest_preds))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,forest_preds))\n",
    "\n",
    "print(\"Accuracy Score: \")\n",
    "print(accuracy_score(y_test,forest_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_trainSc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85        31\n",
      "           1       0.84      0.87      0.85        30\n",
      "\n",
      "    accuracy                           0.85        61\n",
      "   macro avg       0.85      0.85      0.85        61\n",
      "weighted avg       0.85      0.85      0.85        61\n",
      "\n",
      "Confusion Matrix:\n",
      "[[26  5]\n",
      " [ 4 26]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "knn_preds = knn.predict(X_testSc)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,knn_preds))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,knn_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c22e757bb0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#find best value of k\n",
    "error_rate = []\n",
    "\n",
    "for i in range(1,40):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_trainSc,y_train)\n",
    "    pred_i = knn.predict(X_testSc)\n",
    "    error_rate.append(np.mean(pred_i != y_test))\n",
    "    \n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(range(1,40), error_rate, marker='o', markerfacecolor='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89        31\n",
      "           1       0.87      0.90      0.89        30\n",
      "\n",
      "    accuracy                           0.89        61\n",
      "   macro avg       0.89      0.89      0.89        61\n",
      "weighted avg       0.89      0.89      0.89        61\n",
      "\n",
      "Confusion Matrix:\n",
      "[[27  4]\n",
      " [ 3 27]]\n",
      "Accuracy Score: \n",
      "0.8852459016393442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vvd09\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# From the above graph, k = 3 is the best value for k\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_trainSc,y_train)\n",
    "\n",
    "knn_preds = knn.predict(X_testSc)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,knn_preds))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,knn_preds))\n",
    "\n",
    "print(\"Accuracy Score: \")\n",
    "print(accuracy_score(y_test,knn_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #Support Vector Machine - Linear\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model = SVC(kernel = 'linear')\n",
    "svm_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_preds = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.74      0.82        31\n",
      "           1       0.78      0.93      0.85        30\n",
      "\n",
      "    accuracy                           0.84        61\n",
      "   macro avg       0.85      0.84      0.83        61\n",
      "weighted avg       0.85      0.84      0.83        61\n",
      "\n",
      "Confusion Matrix:\n",
      "[[23  8]\n",
      " [ 2 28]]\n",
      "Accuracy Score: \n",
      "0.8360655737704918\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,svm_preds))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,svm_preds))\n",
    "\n",
    "print(\"Accuracy Score: \")\n",
    "print(accuracy_score(y_test,svm_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Svm Kernel RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = SVC(kernel='rbf', random_state=0)\n",
    "svm_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.32      0.45        31\n",
      "           1       0.56      0.90      0.69        30\n",
      "\n",
      "    accuracy                           0.61        61\n",
      "   macro avg       0.67      0.61      0.57        61\n",
      "weighted avg       0.67      0.61      0.57        61\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10 21]\n",
      " [ 3 27]]\n",
      "Accuracy Score: \n",
      "0.6065573770491803\n"
     ]
    }
   ],
   "source": [
    "svm_preds = svm_model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,svm_preds))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,svm_preds))\n",
    "\n",
    "print(\"Accuracy Score: \")\n",
    "print(accuracy_score(y_test,svm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ....................C=0.1, gamma=1;, score=0.551 total time=   0.0s\n",
      "[CV 2/5] END ....................C=0.1, gamma=1;, score=0.551 total time=   0.0s\n",
      "[CV 3/5] END ....................C=0.1, gamma=1;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END ....................C=0.1, gamma=1;, score=0.562 total time=   0.0s\n",
      "[CV 5/5] END ....................C=0.1, gamma=1;, score=0.562 total time=   0.0s\n",
      "[CV 1/5] END ..................C=0.1, gamma=0.1;, score=0.551 total time=   0.0s\n",
      "[CV 2/5] END ..................C=0.1, gamma=0.1;, score=0.551 total time=   0.0s\n",
      "[CV 3/5] END ..................C=0.1, gamma=0.1;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END ..................C=0.1, gamma=0.1;, score=0.562 total time=   0.0s\n",
      "[CV 5/5] END ..................C=0.1, gamma=0.1;, score=0.562 total time=   0.0s\n",
      "[CV 1/5] END .................C=0.1, gamma=0.01;, score=0.551 total time=   0.0s\n",
      "[CV 2/5] END .................C=0.1, gamma=0.01;, score=0.551 total time=   0.0s\n",
      "[CV 3/5] END .................C=0.1, gamma=0.01;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END .................C=0.1, gamma=0.01;, score=0.562 total time=   0.0s\n",
      "[CV 5/5] END .................C=0.1, gamma=0.01;, score=0.562 total time=   0.0s\n",
      "[CV 1/5] END ................C=0.1, gamma=0.001;, score=0.551 total time=   0.0s\n",
      "[CV 2/5] END ................C=0.1, gamma=0.001;, score=0.551 total time=   0.0s\n",
      "[CV 3/5] END ................C=0.1, gamma=0.001;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END ................C=0.1, gamma=0.001;, score=0.562 total time=   0.0s\n",
      "[CV 5/5] END ................C=0.1, gamma=0.001;, score=0.562 total time=   0.0s\n",
      "[CV 1/5] END ...............C=0.1, gamma=0.0001;, score=0.571 total time=   0.0s\n",
      "[CV 2/5] END ...............C=0.1, gamma=0.0001;, score=0.612 total time=   0.0s\n",
      "[CV 3/5] END ...............C=0.1, gamma=0.0001;, score=0.646 total time=   0.0s\n",
      "[CV 4/5] END ...............C=0.1, gamma=0.0001;, score=0.625 total time=   0.0s\n",
      "[CV 5/5] END ...............C=0.1, gamma=0.0001;, score=0.604 total time=   0.0s\n",
      "[CV 1/5] END ......................C=1, gamma=1;, score=0.551 total time=   0.0s\n",
      "[CV 2/5] END ......................C=1, gamma=1;, score=0.551 total time=   0.0s\n",
      "[CV 3/5] END ......................C=1, gamma=1;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END ......................C=1, gamma=1;, score=0.562 total time=   0.0s\n",
      "[CV 5/5] END ......................C=1, gamma=1;, score=0.562 total time=   0.0s\n",
      "[CV 1/5] END ....................C=1, gamma=0.1;, score=0.551 total time=   0.0s\n",
      "[CV 2/5] END ....................C=1, gamma=0.1;, score=0.551 total time=   0.0s\n",
      "[CV 3/5] END ....................C=1, gamma=0.1;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END ....................C=1, gamma=0.1;, score=0.562 total time=   0.0s\n",
      "[CV 5/5] END ....................C=1, gamma=0.1;, score=0.562 total time=   0.0s\n",
      "[CV 1/5] END ...................C=1, gamma=0.01;, score=0.531 total time=   0.0s\n",
      "[CV 2/5] END ...................C=1, gamma=0.01;, score=0.510 total time=   0.0s\n",
      "[CV 3/5] END ...................C=1, gamma=0.01;, score=0.521 total time=   0.0s\n",
      "[CV 4/5] END ...................C=1, gamma=0.01;, score=0.479 total time=   0.0s\n",
      "[CV 5/5] END ...................C=1, gamma=0.01;, score=0.542 total time=   0.0s\n",
      "[CV 1/5] END ..................C=1, gamma=0.001;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END ..................C=1, gamma=0.001;, score=0.592 total time=   0.0s\n",
      "[CV 3/5] END ..................C=1, gamma=0.001;, score=0.708 total time=   0.0s\n",
      "[CV 4/5] END ..................C=1, gamma=0.001;, score=0.562 total time=   0.0s\n",
      "[CV 5/5] END ..................C=1, gamma=0.001;, score=0.604 total time=   0.0s\n",
      "[CV 1/5] END .................C=1, gamma=0.0001;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END .................C=1, gamma=0.0001;, score=0.571 total time=   0.0s\n",
      "[CV 3/5] END .................C=1, gamma=0.0001;, score=0.688 total time=   0.0s\n",
      "[CV 4/5] END .................C=1, gamma=0.0001;, score=0.625 total time=   0.0s\n",
      "[CV 5/5] END .................C=1, gamma=0.0001;, score=0.646 total time=   0.0s\n",
      "[CV 1/5] END .....................C=10, gamma=1;, score=0.551 total time=   0.0s\n",
      "[CV 2/5] END .....................C=10, gamma=1;, score=0.551 total time=   0.0s\n",
      "[CV 3/5] END .....................C=10, gamma=1;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END .....................C=10, gamma=1;, score=0.562 total time=   0.0s\n",
      "[CV 5/5] END .....................C=10, gamma=1;, score=0.562 total time=   0.0s\n",
      "[CV 1/5] END ...................C=10, gamma=0.1;, score=0.551 total time=   0.0s\n",
      "[CV 2/5] END ...................C=10, gamma=0.1;, score=0.531 total time=   0.0s\n",
      "[CV 3/5] END ...................C=10, gamma=0.1;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END ...................C=10, gamma=0.1;, score=0.562 total time=   0.0s\n",
      "[CV 5/5] END ...................C=10, gamma=0.1;, score=0.562 total time=   0.0s\n",
      "[CV 1/5] END ..................C=10, gamma=0.01;, score=0.531 total time=   0.0s\n",
      "[CV 2/5] END ..................C=10, gamma=0.01;, score=0.510 total time=   0.0s\n",
      "[CV 3/5] END ..................C=10, gamma=0.01;, score=0.542 total time=   0.0s\n",
      "[CV 4/5] END ..................C=10, gamma=0.01;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ..................C=10, gamma=0.01;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END .................C=10, gamma=0.001;, score=0.633 total time=   0.0s\n",
      "[CV 2/5] END .................C=10, gamma=0.001;, score=0.653 total time=   0.0s\n",
      "[CV 3/5] END .................C=10, gamma=0.001;, score=0.625 total time=   0.0s\n",
      "[CV 4/5] END .................C=10, gamma=0.001;, score=0.562 total time=   0.0s\n",
      "[CV 5/5] END .................C=10, gamma=0.001;, score=0.583 total time=   0.0s\n",
      "[CV 1/5] END ................C=10, gamma=0.0001;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END ................C=10, gamma=0.0001;, score=0.612 total time=   0.0s\n",
      "[CV 3/5] END ................C=10, gamma=0.0001;, score=0.771 total time=   0.0s\n",
      "[CV 4/5] END ................C=10, gamma=0.0001;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END ................C=10, gamma=0.0001;, score=0.688 total time=   0.0s\n",
      "[CV 1/5] END ....................C=100, gamma=1;, score=0.551 total time=   0.0s\n",
      "[CV 2/5] END ....................C=100, gamma=1;, score=0.551 total time=   0.0s\n",
      "[CV 3/5] END ....................C=100, gamma=1;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END ....................C=100, gamma=1;, score=0.562 total time=   0.0s\n",
      "[CV 5/5] END ....................C=100, gamma=1;, score=0.562 total time=   0.0s\n",
      "[CV 1/5] END ..................C=100, gamma=0.1;, score=0.551 total time=   0.0s\n",
      "[CV 2/5] END ..................C=100, gamma=0.1;, score=0.531 total time=   0.0s\n",
      "[CV 3/5] END ..................C=100, gamma=0.1;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END ..................C=100, gamma=0.1;, score=0.562 total time=   0.0s\n",
      "[CV 5/5] END ..................C=100, gamma=0.1;, score=0.562 total time=   0.0s\n",
      "[CV 1/5] END .................C=100, gamma=0.01;, score=0.531 total time=   0.0s\n",
      "[CV 2/5] END .................C=100, gamma=0.01;, score=0.510 total time=   0.0s\n",
      "[CV 3/5] END .................C=100, gamma=0.01;, score=0.542 total time=   0.0s\n",
      "[CV 4/5] END .................C=100, gamma=0.01;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END .................C=100, gamma=0.01;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END ................C=100, gamma=0.001;, score=0.551 total time=   0.0s\n",
      "[CV 2/5] END ................C=100, gamma=0.001;, score=0.653 total time=   0.0s\n",
      "[CV 3/5] END ................C=100, gamma=0.001;, score=0.688 total time=   0.0s\n",
      "[CV 4/5] END ................C=100, gamma=0.001;, score=0.542 total time=   0.0s\n",
      "[CV 5/5] END ................C=100, gamma=0.001;, score=0.562 total time=   0.0s\n",
      "[CV 1/5] END ...............C=100, gamma=0.0001;, score=0.776 total time=   0.0s\n",
      "[CV 2/5] END ...............C=100, gamma=0.0001;, score=0.735 total time=   0.0s\n",
      "[CV 3/5] END ...............C=100, gamma=0.0001;, score=0.854 total time=   0.0s\n",
      "[CV 4/5] END ...............C=100, gamma=0.0001;, score=0.708 total time=   0.0s\n",
      "[CV 5/5] END ...............C=100, gamma=0.0001;, score=0.812 total time=   0.0s\n",
      "[CV 1/5] END ...................C=1000, gamma=1;, score=0.551 total time=   0.0s\n",
      "[CV 2/5] END ...................C=1000, gamma=1;, score=0.551 total time=   0.0s\n",
      "[CV 3/5] END ...................C=1000, gamma=1;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END ...................C=1000, gamma=1;, score=0.562 total time=   0.0s\n",
      "[CV 5/5] END ...................C=1000, gamma=1;, score=0.562 total time=   0.0s\n",
      "[CV 1/5] END .................C=1000, gamma=0.1;, score=0.551 total time=   0.0s\n",
      "[CV 2/5] END .................C=1000, gamma=0.1;, score=0.531 total time=   0.0s\n",
      "[CV 3/5] END .................C=1000, gamma=0.1;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END .................C=1000, gamma=0.1;, score=0.562 total time=   0.0s\n",
      "[CV 5/5] END .................C=1000, gamma=0.1;, score=0.562 total time=   0.0s\n",
      "[CV 1/5] END ................C=1000, gamma=0.01;, score=0.531 total time=   0.0s\n",
      "[CV 2/5] END ................C=1000, gamma=0.01;, score=0.510 total time=   0.0s\n",
      "[CV 3/5] END ................C=1000, gamma=0.01;, score=0.542 total time=   0.0s\n",
      "[CV 4/5] END ................C=1000, gamma=0.01;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ................C=1000, gamma=0.01;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END ...............C=1000, gamma=0.001;, score=0.510 total time=   0.0s\n",
      "[CV 2/5] END ...............C=1000, gamma=0.001;, score=0.612 total time=   0.0s\n",
      "[CV 3/5] END ...............C=1000, gamma=0.001;, score=0.646 total time=   0.0s\n",
      "[CV 4/5] END ...............C=1000, gamma=0.001;, score=0.479 total time=   0.0s\n",
      "[CV 5/5] END ...............C=1000, gamma=0.001;, score=0.521 total time=   0.0s\n",
      "[CV 1/5] END ..............C=1000, gamma=0.0001;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END ..............C=1000, gamma=0.0001;, score=0.714 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..............C=1000, gamma=0.0001;, score=0.708 total time=   0.0s\n",
      "[CV 4/5] END ..............C=1000, gamma=0.0001;, score=0.688 total time=   0.0s\n",
      "[CV 5/5] END ..............C=1000, gamma=0.0001;, score=0.792 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find most optimal params\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C':[0.1,1,10,100,1000],'gamma':[1,0.1,0.01,0.001,0.0001]}\n",
    "grid = GridSearchCV(SVC(), param_grid, verbose=3)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for SVM RBF: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'gamma': 0.0001}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"best params for SVM RBF: \")\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, gamma=0.0001, random_state=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = SVC(kernel='rbf', random_state=0, C=100, gamma=0.0001)\n",
    "svm_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.68      0.79        31\n",
      "           1       0.74      0.97      0.84        30\n",
      "\n",
      "    accuracy                           0.82        61\n",
      "   macro avg       0.85      0.82      0.82        61\n",
      "weighted avg       0.85      0.82      0.82        61\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21 10]\n",
      " [ 1 29]]\n",
      "Accuracy Score: \n",
      "0.819672131147541\n"
     ]
    }
   ],
   "source": [
    "svm_preds = svm_model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,svm_preds))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,svm_preds))\n",
    "\n",
    "print(\"Accuracy Score: \")\n",
    "print(accuracy_score(y_test,svm_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "tree.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.77      0.83        31\n",
      "           1       0.79      0.90      0.84        30\n",
      "\n",
      "    accuracy                           0.84        61\n",
      "   macro avg       0.84      0.84      0.84        61\n",
      "weighted avg       0.84      0.84      0.84        61\n",
      "\n",
      "Confusion Matrix:\n",
      "[[24  7]\n",
      " [ 3 27]]\n",
      "Accuracy Score: \n",
      "0.8360655737704918\n"
     ]
    }
   ],
   "source": [
    "tree_preds = tree.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,tree_preds))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,tree_preds))\n",
    "\n",
    "print(\"Accuracy Score: \")\n",
    "print(accuracy_score(y_test,tree_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
